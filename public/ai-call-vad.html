<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Call - Simple VAD</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
    }
    .container {
      background: white;
      border-radius: 15px;
      padding: 30px;
      box-shadow: 0 10px 40px rgba(0,0,0,0.3);
    }
    h1 { text-align: center; color: #333; margin-bottom: 30px; }
    
    .controls {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-bottom: 30px;
    }
    button {
      padding: 15px 30px;
      font-size: 16px;
      font-weight: bold;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.3s;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    button:hover:not(:disabled) {
      transform: translateY(-2px);
      box-shadow: 0 6px 12px rgba(0,0,0,0.2);
    }
    button:disabled { opacity: 0.5; cursor: not-allowed; }
    #startCall { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
    #endCall { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; }
    
    .status-box {
      background: #f8f9fa;
      border-left: 4px solid #667eea;
      padding: 20px;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    #status { font-size: 18px; font-weight: bold; color: #667eea; }

    .info-grid {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 15px;
      margin-bottom: 20px;
    }
    .info-card {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 20px;
      border-radius: 10px;
      text-align: center;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .info-label { font-size: 12px; opacity: 0.9; margin-bottom: 5px; }
    .info-value { font-size: 24px; font-weight: bold; }

    .log-box {
      background: #1e1e1e;
      color: #d4d4d4;
      padding: 20px;
      border-radius: 8px;
      max-height: 500px;
      overflow-y: auto;
      font-family: 'Courier New', monospace;
      font-size: 13px;
      line-height: 1.8;
    }
    .log-entry { margin-bottom: 5px; padding: 6px 10px; border-radius: 4px; border-left: 3px solid transparent; }
    .log-entry.info { border-color: #4CAF50; color: #4CAF50; }
    .log-entry.warning { border-color: #FFC107; color: #FFC107; }
    .log-entry.error { border-color: #F44336; color: #F44336; background: rgba(244,67,54,0.1); }
    .log-entry.success { border-color: #00E676; color: #00E676; font-weight: bold; }
    .log-entry.debug { border-color: #666; color: #666; opacity: 0.7; }
  </style>
</head>
<body>
  <div class="container">
    <h1>ğŸ¤– AI ì „í™” ì‹œìŠ¤í…œ (ê°„ì†Œí™” ë²„ì „)</h1>
    
    <div class="controls">
      <button id="startCall">ğŸ“ í†µí™” ì‹œì‘</button>
      <button id="endCall" disabled>ğŸ“´ í†µí™” ì¢…ë£Œ</button>
      <button onclick="clearLogs()">ğŸ—‘ï¸ ë¡œê·¸ ì§€ìš°ê¸°</button>
    </div>

    <div class="status-box">
      <div id="status">ëŒ€ê¸° ì¤‘...</div>
    </div>

    <div class="info-grid">
      <div class="info-card">
        <div class="info-label">ìŒëŸ‰ (dB)</div>
        <div id="volumeLevel" class="info-value">-âˆ</div>
      </div>
      <div class="info-card">
        <div class="info-label">VAD ìƒíƒœ</div>
        <div id="vadStatus" class="info-value">ëŒ€ê¸°</div>
      </div>
      <div class="info-card">
        <div class="info-label">ì „ì†¡ íšŸìˆ˜</div>
        <div id="audioSent" class="info-value">0</div>
      </div>
      <div class="info-card">
        <div class="info-label">AI ì‘ë‹µ</div>
        <div id="aiResponses" class="info-value">0</div>
      </div>
    </div>

    <h3 style="margin-top: 30px;">ğŸ“‹ ìƒì„¸ ë¡œê·¸</h3>
    <div id="logBox" class="log-box"></div>
    
    <audio id="remoteAudio" autoplay></audio>
  </div>

  <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
  <script>
    let socket, callId, sessionId, localStream, peerConnection;
    let audioContext, analyser, mediaRecorder;
    let recordedChunks = [], isRecording = false, isAIResponding = false;
    let audioSentCount = 0, aiResponseCount = 0;
    let vadCheckInterval = null;

    const VOLUME_THRESHOLD = -35; // dB (ë” ì—„ê²©í•˜ê²Œ)
    const SILENCE_DURATION = 1000; // 1ì´ˆ
    const CHECK_INTERVAL = 100; // 100ms

    let lastSpeechTime = 0;
    let isSpeaking = false;

    const log = (msg, type='info') => {
      const time = new Date().toLocaleTimeString('ko-KR');
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      entry.innerHTML = `<span style="color:#666">[${time}]</span> ${msg}`;
      logBox.appendChild(entry);
      logBox.scrollTop = logBox.scrollHeight;
      console.log(`[${time}] [${type.toUpperCase()}] ${msg}`);
    };

    const clearLogs = () => {
      logBox.innerHTML = '';
      log('ë¡œê·¸ ì´ˆê¸°í™”ë¨', 'info');
    };

    // ìŒëŸ‰ ì¸¡ì •
    function getVolume() {
      if (!analyser) return -100;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);
      
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += dataArray[i] * dataArray[i];
      }
      const rms = Math.sqrt(sum / dataArray.length);
      const db = 20 * Math.log10(rms / 255);
      
      return isFinite(db) ? db : -100;
    }

    // VAD ì²´í¬
    function startVADChecking() {
      log('ğŸ¤ VAD ì²´í¬ ì‹œì‘ (ê°„ì†Œí™” ë²„ì „)', 'info');
      
      vadCheckInterval = setInterval(() => {
        if (!localStream || isAIResponding) {
          if (isAIResponding) {
            vadStatus.textContent = 'ğŸ¤–';
            volumeLevel.textContent = 'AI';
          }
          return;
        }

        const volume = getVolume();
        volumeLevel.textContent = volume.toFixed(1);

        // ìŒì„± ê°ì§€
        if (volume > VOLUME_THRESHOLD) {
          if (!isSpeaking) {
            log(`ğŸ™ï¸ ìŒì„± ê°ì§€! (${volume.toFixed(1)}dB > ${VOLUME_THRESHOLD}dB)`, 'success');
            vadStatus.textContent = 'ğŸ—£ï¸';
            isSpeaking = true;
            
            if (!isRecording) {
              startRecording();
            }
          }
          lastSpeechTime = Date.now();
        } else {
          // ì¹¨ë¬µ ì²´í¬
          if (isSpeaking && (Date.now() - lastSpeechTime > SILENCE_DURATION)) {
            log(`ğŸ”‡ ì¹¨ë¬µ ê°ì§€ (${((Date.now() - lastSpeechTime)/1000).toFixed(1)}ì´ˆ)`, 'info');
            vadStatus.textContent = 'â¸ï¸';
            isSpeaking = false;
            
            if (isRecording) {
              stopRecording();
            }
          }
        }

        // ëŒ€ê¸° ì¤‘
        if (!isSpeaking && !isAIResponding) {
          vadStatus.textContent = 'ğŸ’¤';
        }

      }, CHECK_INTERVAL);
    }

    function startRecording() {
      if (isRecording || !localStream) return;
      
      log('âºï¸ ë…¹ìŒ ì‹œì‘', 'info');
      recordedChunks = [];

      try {
        mediaRecorder = new MediaRecorder(localStream, { mimeType: 'audio/webm;codecs=opus' });
        
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            recordedChunks.push(e.data);
            log(`ğŸ“¦ ì²­í¬: ${(e.data.size/1024).toFixed(1)}KB`, 'debug');
          }
        };

        mediaRecorder.onstop = () => {
          const blob = new Blob(recordedChunks, { type: 'audio/webm' });
          log(`â¹ï¸ ë…¹ìŒ ì™„ë£Œ: ${(blob.size/1024).toFixed(1)}KB`, 'info');
          sendAudio(blob);
        };

        mediaRecorder.start();
        isRecording = true;
      } catch (e) {
        log(`âŒ ë…¹ìŒ ì‹¤íŒ¨: ${e.message}`, 'error');
      }
    }

    function stopRecording() {
      if (!isRecording || !mediaRecorder) return;
      try {
        mediaRecorder.stop();
        isRecording = false;
      } catch (e) {
        log(`âŒ ì¤‘ì§€ ì‹¤íŒ¨: ${e.message}`, 'error');
      }
    }

    function sendAudio(blob) {
      if (isAIResponding) {
        log('âš ï¸ AI ì‘ë‹µ ì¤‘ - ì „ì†¡ ì·¨ì†Œ', 'warning');
        return;
      }

      if (blob.size < 15000) {
        log(`âš ï¸ ë„ˆë¬´ ì‘ìŒ: ${(blob.size/1024).toFixed(1)}KB < 15KB`, 'warning');
        return;
      }

      log(`ğŸ“¤ ì „ì†¡ ì¤‘... (${(blob.size/1024).toFixed(1)}KB)`, 'info');

      const reader = new FileReader();
      reader.onloadend = () => {
        socket.emit('user-audio', {
          sessionId, callId,
          audioData: reader.result.split(',')[1],
          mimeType: 'audio/webm'
        });
        audioSentCount++;
        audioSent.textContent = audioSentCount;
        log(`âœ… ì „ì†¡ ì™„ë£Œ! (#${audioSentCount})`, 'success');
      };
      reader.readAsDataURL(blob);
    }

    startCall.onclick = async () => {
      try {
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'info');
        log('ğŸš€ í†µí™” ì‹œì‘!', 'success');
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'info');
        status.textContent = 'ì—°ê²° ì¤‘...';

        // 1. ì„¤ì •
        log('1ï¸âƒ£ WebRTC ì„¤ì • ì¡°íšŒ...', 'info');
        const cfgRes = await fetch('http://localhost:3000/api/v1/calls/config');
        const cfg = await cfgRes.json();
        log(`âœ… ì‘ë‹µ: ${JSON.stringify(cfg).substring(0, 100)}...`, 'debug');
        
        if (!cfg.success || !cfg.data || !cfg.data.config) {
          throw new Error('ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: ' + JSON.stringify(cfg));
        }
        log('âœ… ì„¤ì • ì¡°íšŒ ì™„ë£Œ', 'success');

        // 2. í†µí™” ìƒì„±
        log('2ï¸âƒ£ í†µí™” ìƒì„±...', 'info');
        const callRes = await fetch('http://localhost:3000/api/v1/calls', {
          method: 'POST',
          headers: {'Content-Type': 'application/json'},
          body: JSON.stringify({callerNumber: '01012345678'})
        });
        
        const callText = await callRes.text();
        log(`âœ… API ì‘ë‹µ: ${callText.substring(0, 200)}`, 'debug');
        
        let call;
        try {
          call = JSON.parse(callText);
        } catch (e) {
          throw new Error('JSON íŒŒì‹± ì‹¤íŒ¨: ' + callText);
        }

        if (!call.success) {
          throw new Error('í†µí™” ìƒì„± ì‹¤íŒ¨: ' + (call.message || JSON.stringify(call)));
        }

        if (!call.data || !call.data.call) {
          throw new Error('ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜: ' + JSON.stringify(call));
        }

        callId = call.data.call.id;
        sessionId = call.data.call.sessionId;
        
        log(`âœ… Call ID: ${callId}`, 'success');
        log(`âœ… Session ID: ${sessionId}`, 'success');

        // 3. WebSocket
        log('3ï¸âƒ£ WebSocket ì—°ê²°...', 'info');
        socket = io('http://localhost:3000/signaling');
        
        socket.on('connect', () => log('âœ… WebSocket ì—°ê²°ë¨', 'success'));
        socket.on('error', (e) => log(`âŒ Socket ì—ëŸ¬: ${JSON.stringify(e)}`, 'error'));
        
        socket.on('ai-audio-response', ({audioData}) => {
          log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'success');
          log('ğŸ¤– AI ì‘ë‹µ ìˆ˜ì‹ !', 'success');
          log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'success');
          
          isAIResponding = true;
          vadStatus.textContent = 'ğŸ¤–';
          status.textContent = 'ğŸ¤– AIê°€ ë§í•˜ëŠ” ì¤‘...';

          const bytes = atob(audioData).split('').map(c => c.charCodeAt(0));
          const blob = new Blob([new Uint8Array(bytes)], {type: 'audio/mp3'});
          const audio = new Audio(URL.createObjectURL(blob));
          
          audio.onended = () => {
            isAIResponding = false;
            aiResponseCount++;
            aiResponses.textContent = aiResponseCount;
            log(`âœ… AI ì‘ë‹µ ì¬ìƒ ì™„ë£Œ (#${aiResponseCount})`, 'success');
            vadStatus.textContent = 'ğŸ’¤';
            status.textContent = 'âœ… í†µí™” ì¤‘ - ë§ì”€í•˜ì„¸ìš”';
          };
          
          audio.onerror = (e) => {
            isAIResponding = false;
            log(`âŒ AI ì¬ìƒ ì‹¤íŒ¨: ${JSON.stringify(e)}`, 'error');
          };

          audio.play();
          log('ğŸ”Š AI ì‘ë‹µ ì¬ìƒ ì‹œì‘', 'info');
        });

        // 4. ë§ˆì´í¬
        log('4ï¸âƒ£ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...', 'info');
        localStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 48000
          }
        });
        log('âœ… ë§ˆì´í¬ í—ˆìš©ë¨', 'success');

        // AudioContext
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        analyser.smoothingTimeConstant = 0.8;
        const source = audioContext.createMediaStreamSource(localStream);
        source.connect(analyser);
        log('âœ… AudioContext ì´ˆê¸°í™”', 'success');

        // 5. PeerConnection
        log('5ï¸âƒ£ WebRTC Peer ìƒì„±...', 'info');
        peerConnection = new RTCPeerConnection(cfg.data.config);
        
        localStream.getTracks().forEach(t => peerConnection.addTrack(t, localStream));
        log('âœ… íŠ¸ë™ ì¶”ê°€ ì™„ë£Œ', 'success');

        peerConnection.onicecandidate = (e) => {
          if (e.candidate) {
            socket.emit('ice-candidate', {sessionId, peerId: 'client', candidate: e.candidate});
            log('ğŸ§Š ICE candidate ì „ì†¡', 'debug');
          }
        };

        peerConnection.onconnectionstatechange = () => {
          log(`ğŸ”— ì—°ê²° ìƒíƒœ: ${peerConnection.connectionState}`, 'info');
        };

        // 6. ì„¸ì…˜ ì°¸ì—¬
        log('6ï¸âƒ£ ì„¸ì…˜ ì°¸ì—¬...', 'info');
        socket.emit('join-session', {sessionId, peerId: 'client', callId});
        
        socket.on('joined-session', () => log('âœ… ì„¸ì…˜ ì°¸ì—¬ ì™„ë£Œ', 'success'));

        // 7. Offer
        log('7ï¸âƒ£ WebRTC Offer ìƒì„±...', 'info');
        const offer = await peerConnection.createOffer();
        await peerConnection.setLocalDescription(offer);
        socket.emit('offer', {sessionId, peerId: 'client', offer});
        log('âœ… Offer ì „ì†¡ ì™„ë£Œ', 'success');

        socket.on('answer', async ({answer}) => {
          await peerConnection.setRemoteDescription(answer);
          log('âœ… Answer ìˆ˜ì‹  ë° ì„¤ì •', 'success');
        });

        socket.on('ice-candidate', async ({candidate}) => {
          await peerConnection.addIceCandidate(candidate);
          log('ğŸ§Š ICE candidate ìˆ˜ì‹ ', 'debug');
        });

        // 8. í†µí™” ì—°ê²°
        log('8ï¸âƒ£ í†µí™” ì—°ê²° API í˜¸ì¶œ...', 'info');
        await fetch(`http://localhost:3000/api/v1/calls/${callId}/connect`, {method: 'POST'});
        log('âœ… í†µí™” ì—°ê²° ì™„ë£Œ', 'success');

        // 9. VAD ì‹œì‘
        log('9ï¸âƒ£ VAD ì‹œì‘...', 'info');
        startVADChecking();
        log(`âœ… VAD í™œì„±í™” (ì„ê³„ê°’: ${VOLUME_THRESHOLD}dB)`, 'success');

        // ì™„ë£Œ
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'success');
        log('ğŸ‰ ëª¨ë“  ì´ˆê¸°í™” ì™„ë£Œ!', 'success');
        log('ğŸ™ï¸ ë§ì”€í•˜ì‹œë©´ AIê°€ ì‘ë‹µí•©ë‹ˆë‹¤', 'success');
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'success');

        startCall.disabled = true;
        endCall.disabled = false;
        status.textContent = 'âœ… í†µí™” ì¤‘ - ë§ì”€í•˜ì„¸ìš”!';
        status.style.color = '#4CAF50';

      } catch (e) {
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'error');
        log(`âŒ ì—ëŸ¬: ${e.message}`, 'error');
        log(`ìŠ¤íƒ: ${e.stack}`, 'error');
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'error');
        status.textContent = 'âŒ ì—°ê²° ì‹¤íŒ¨';
        status.style.color = '#F44336';
      }
    };

    endCall.onclick = async () => {
      try {
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'info');
        log('ğŸ›‘ í†µí™” ì¢…ë£Œ ì‹œì‘', 'info');

        if (vadCheckInterval) {
          clearInterval(vadCheckInterval);
          log('âœ… VAD ì¤‘ì§€', 'success');
        }

        if (isRecording && mediaRecorder) {
          mediaRecorder.stop();
          log('âœ… ë…¹ìŒ ì¤‘ì§€', 'success');
        }

        if (audioContext) {
          await audioContext.close();
          log('âœ… AudioContext ì¢…ë£Œ', 'success');
        }

        if (callId) {
          await fetch(`http://localhost:3000/api/v1/calls/${callId}/end`, {method: 'POST'});
          log('âœ… í†µí™” ì¢…ë£Œ API í˜¸ì¶œ', 'success');
        }

        if (peerConnection) {
          peerConnection.close();
          log('âœ… PeerConnection ì¢…ë£Œ', 'success');
        }

        if (localStream) {
          localStream.getTracks().forEach(t => t.stop());
          log('âœ… ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ', 'success');
        }

        if (socket) {
          socket.disconnect();
          log('âœ… WebSocket ì¢…ë£Œ', 'success');
        }

        audioSentCount = 0;
        aiResponseCount = 0;
        audioSent.textContent = '0';
        aiResponses.textContent = '0';
        volumeLevel.textContent = '-âˆ';
        vadStatus.textContent = 'ëŒ€ê¸°';
        callId = null;
        sessionId = null;

        startCall.disabled = false;
        endCall.disabled = true;
        status.textContent = 'í†µí™” ì¢…ë£Œë¨';
        status.style.color = '#666';

        log('âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ', 'success');
        log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'success');

      } catch (e) {
        log(`âŒ ì¢…ë£Œ ì¤‘ ì—ëŸ¬: ${e.message}`, 'error');
      }
    };

    // ì´ˆê¸° ë¡œê·¸
    log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'info');
    log('ğŸ¬ AI ì „í™” ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ', 'success');
    log('ğŸ“Œ "í†µí™” ì‹œì‘" ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”', 'info');
    log(`âš™ï¸ ì„¤ì •: ì„ê³„ê°’ ${VOLUME_THRESHOLD}dB, ì¹¨ë¬µ ${SILENCE_DURATION}ms`, 'info');
    log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', 'info');
  </script>
</body>
</html>
